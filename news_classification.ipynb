{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News category Classification \n",
    "\n",
    "FEATURES:\n",
    "\n",
    "STORY:  A part of the main content of the article to be published as a piece of news.\n",
    "SECTION: The genre/category the STORY falls in.\n",
    "\n",
    "There are four distinct sections where each story may fall in to. The Sections are labelled as follows :\n",
    "\n",
    "Politics: 0\n",
    "\n",
    "Technology: 1\n",
    "\n",
    "Entertainment: 2\n",
    "\n",
    "Business: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('news_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the most painful was the huge reversal in ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How formidable is the opposition alliance amon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most Asian currencies were trading lower today...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you want to answer any question, click on ‘...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In global markets, gold prices edged up today ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               STORY  SECTION\n",
       "0  But the most painful was the huge reversal in ...        3\n",
       "1  How formidable is the opposition alliance amon...        0\n",
       "2  Most Asian currencies were trading lower today...        3\n",
       "3  If you want to answer any question, click on ‘...        1\n",
       "4  In global markets, gold prices edged up today ...        3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:1].values\n",
    "Y = df.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7628, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7628, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train ,Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 300\n",
    "classes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading glove vectors from a file\n",
    "\n",
    "Download Pre-trained word vectors form http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove(file):\n",
    "    with open(file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_index, index_to_words, word_to_vec_map = read_glove(\"glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting sentence into respective indices using glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen_to_index(X, words_to_index, maxlen):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, maxlen))\n",
    "    for i in range(0, m):\n",
    "        sent = X[i][0].replace('’', '').translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "        j = 0\n",
    "        for w in sent:\n",
    "            if w in words_to_index.keys():\n",
    "                X_indices[i, j] = words_to_index[w]\n",
    "            else:\n",
    "                X_indices[i, j] = words_to_index['unk']\n",
    "            j = j + 1\n",
    "            if j == maxlen:\n",
    "                break\n",
    "    return X_indices   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load require libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(word_to_vec_map, words_to_index):\n",
    "    \n",
    "    vocab = len(words_to_index) + 1\n",
    "    vec_size = len(word_to_vec_map[\"news\"])\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab, vec_size))\n",
    "    \n",
    "    for w, i in words_to_index.items():\n",
    "        embedding_matrix[i, :] = word_to_vec_map[w]\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim = vocab, output_dim = vec_size, trainable = False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([embedding_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Model for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_classifier(input_shape, word_to_vec_map, words_to_index):\n",
    "    \n",
    "    sen_indices = Input(input_shape, dtype = 'int32')\n",
    "    \n",
    "    embedding_layer = embedding(word_to_vec_map, words_to_index)\n",
    "    \n",
    "    embeddings = embedding_layer(sen_indices)\n",
    "    \n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(4)(X)\n",
    "    X = Activation(\"softmax\")(X)\n",
    "    \n",
    "    model = Model(sen_indices, X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tushar/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/tushar/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 300, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300, 128)          91648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,798\n",
      "Trainable params: 223,748\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = news_classifier((maxlen,), word_to_vec_map, words_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sen_to_index(X_train, words_to_index, maxlen)\n",
    "Y_train_oh = np.eye(classes)[Y_train.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tushar/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "6102/6102 [==============================] - 52s 9ms/step - loss: 1.3419 - acc: 0.3622\n",
      "Epoch 2/100\n",
      "6102/6102 [==============================] - 57s 9ms/step - loss: 1.2284 - acc: 0.4584\n",
      "Epoch 3/100\n",
      "6102/6102 [==============================] - 55s 9ms/step - loss: 1.2959 - acc: 0.4200\n",
      "Epoch 4/100\n",
      "6102/6102 [==============================] - 55s 9ms/step - loss: 1.2041 - acc: 0.4920\n",
      "Epoch 5/100\n",
      "6102/6102 [==============================] - 59s 10ms/step - loss: 1.1713 - acc: 0.5051\n",
      "Epoch 6/100\n",
      "6102/6102 [==============================] - 54s 9ms/step - loss: 1.0954 - acc: 0.5238\n",
      "Epoch 7/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 1.0087 - acc: 0.6103\n",
      "Epoch 8/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 1.0525 - acc: 0.5270\n",
      "Epoch 9/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.9804 - acc: 0.5546\n",
      "Epoch 10/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.8548 - acc: 0.6252\n",
      "Epoch 11/100\n",
      "6102/6102 [==============================] - 57s 9ms/step - loss: 0.8399 - acc: 0.6290\n",
      "Epoch 12/100\n",
      "6102/6102 [==============================] - 54s 9ms/step - loss: 0.8722 - acc: 0.6129\n",
      "Epoch 13/100\n",
      "6102/6102 [==============================] - 54s 9ms/step - loss: 0.9731 - acc: 0.5524\n",
      "Epoch 14/100\n",
      "6102/6102 [==============================] - 54s 9ms/step - loss: 0.8449 - acc: 0.6114\n",
      "Epoch 15/100\n",
      "6102/6102 [==============================] - 55s 9ms/step - loss: 0.7629 - acc: 0.6521\n",
      "Epoch 16/100\n",
      "6102/6102 [==============================] - 55s 9ms/step - loss: 0.8319 - acc: 0.6290\n",
      "Epoch 17/100\n",
      "6102/6102 [==============================] - 57s 9ms/step - loss: 0.7195 - acc: 0.6721\n",
      "Epoch 18/100\n",
      "6102/6102 [==============================] - 56s 9ms/step - loss: 0.7464 - acc: 0.6644\n",
      "Epoch 19/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.7163 - acc: 0.6655\n",
      "Epoch 20/100\n",
      "6102/6102 [==============================] - 58s 9ms/step - loss: 0.6607 - acc: 0.7017\n",
      "Epoch 21/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.6337 - acc: 0.7971\n",
      "Epoch 22/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.5734 - acc: 0.8443\n",
      "Epoch 23/100\n",
      "6102/6102 [==============================] - 64s 10ms/step - loss: 0.5434 - acc: 0.8382\n",
      "Epoch 24/100\n",
      "6102/6102 [==============================] - 76s 12ms/step - loss: 0.6030 - acc: 0.7914\n",
      "Epoch 25/100\n",
      "6102/6102 [==============================] - 73s 12ms/step - loss: 0.4255 - acc: 0.8848\n",
      "Epoch 26/100\n",
      "6102/6102 [==============================] - 70s 11ms/step - loss: 0.3558 - acc: 0.9038\n",
      "Epoch 27/100\n",
      "6102/6102 [==============================] - 72s 12ms/step - loss: 0.3785 - acc: 0.8900\n",
      "Epoch 28/100\n",
      "6102/6102 [==============================] - 72s 12ms/step - loss: 0.4169 - acc: 0.8828\n",
      "Epoch 29/100\n",
      "6102/6102 [==============================] - 68s 11ms/step - loss: 0.4306 - acc: 0.8586\n",
      "Epoch 30/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.4589 - acc: 0.8581\n",
      "Epoch 31/100\n",
      "6102/6102 [==============================] - 52s 9ms/step - loss: 0.5657 - acc: 0.8209\n",
      "Epoch 32/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.4972 - acc: 0.8340\n",
      "Epoch 33/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.4011 - acc: 0.8691\n",
      "Epoch 34/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.4144 - acc: 0.8668\n",
      "Epoch 35/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.3035 - acc: 0.9294\n",
      "Epoch 36/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.6223 - acc: 0.8058\n",
      "Epoch 37/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.3379 - acc: 0.8989\n",
      "Epoch 38/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.2651 - acc: 0.9276\n",
      "Epoch 39/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.2462 - acc: 0.9348\n",
      "Epoch 40/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.2479 - acc: 0.9331\n",
      "Epoch 41/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.2247 - acc: 0.9395\n",
      "Epoch 42/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.2596 - acc: 0.9340\n",
      "Epoch 43/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2573 - acc: 0.9267\n",
      "Epoch 44/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.2776 - acc: 0.9241\n",
      "Epoch 45/100\n",
      "6102/6102 [==============================] - 52s 9ms/step - loss: 0.2288 - acc: 0.9403\n",
      "Epoch 46/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2136 - acc: 0.9443\n",
      "Epoch 47/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.2037 - acc: 0.9438\n",
      "Epoch 48/100\n",
      "6102/6102 [==============================] - 54s 9ms/step - loss: 0.1918 - acc: 0.9472\n",
      "Epoch 49/100\n",
      "6102/6102 [==============================] - 54s 9ms/step - loss: 0.2034 - acc: 0.9484\n",
      "Epoch 50/100\n",
      "6102/6102 [==============================] - 52s 8ms/step - loss: 0.1855 - acc: 0.9499\n",
      "Epoch 51/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2203 - acc: 0.9356\n",
      "Epoch 52/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2091 - acc: 0.9462\n",
      "Epoch 53/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2139 - acc: 0.9413\n",
      "Epoch 54/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2055 - acc: 0.9448\n",
      "Epoch 55/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1980 - acc: 0.9441\n",
      "Epoch 56/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1889 - acc: 0.9459\n",
      "Epoch 57/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2074 - acc: 0.9449\n",
      "Epoch 58/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1945 - acc: 0.9464\n",
      "Epoch 59/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1770 - acc: 0.9538\n",
      "Epoch 60/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1665 - acc: 0.9531\n",
      "Epoch 61/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1594 - acc: 0.9539\n",
      "Epoch 62/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1607 - acc: 0.9562\n",
      "Epoch 63/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.1699 - acc: 0.9559\n",
      "Epoch 64/100\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.1571 - acc: 0.9579\n",
      "Epoch 65/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1768 - acc: 0.9502\n",
      "Epoch 66/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1766 - acc: 0.9487\n",
      "Epoch 67/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1399 - acc: 0.9590\n",
      "Epoch 68/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1365 - acc: 0.9597\n",
      "Epoch 69/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1433 - acc: 0.9585\n",
      "Epoch 70/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1251 - acc: 0.9613\n",
      "Epoch 71/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1287 - acc: 0.9630\n",
      "Epoch 72/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1620 - acc: 0.9546\n",
      "Epoch 73/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1666 - acc: 0.9564\n",
      "Epoch 74/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1392 - acc: 0.9636\n",
      "Epoch 75/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1340 - acc: 0.9608\n",
      "Epoch 76/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1257 - acc: 0.9671\n",
      "Epoch 77/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1221 - acc: 0.9656\n",
      "Epoch 78/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1165 - acc: 0.9671\n",
      "Epoch 79/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1197 - acc: 0.9656\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1289 - acc: 0.9669\n",
      "Epoch 81/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1224 - acc: 0.9690\n",
      "Epoch 82/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1039 - acc: 0.9716\n",
      "Epoch 83/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1963 - acc: 0.9569\n",
      "Epoch 84/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1844 - acc: 0.9492\n",
      "Epoch 85/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1258 - acc: 0.9641\n",
      "Epoch 86/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1327 - acc: 0.9638\n",
      "Epoch 87/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1267 - acc: 0.9674\n",
      "Epoch 88/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1362 - acc: 0.9644\n",
      "Epoch 89/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1170 - acc: 0.9698\n",
      "Epoch 90/100\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1184 - acc: 0.9705\n",
      "Epoch 91/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1148 - acc: 0.9721\n",
      "Epoch 92/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1025 - acc: 0.9721\n",
      "Epoch 93/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.0991 - acc: 0.9738\n",
      "Epoch 94/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.0964 - acc: 0.9736\n",
      "Epoch 95/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1068 - acc: 0.9710\n",
      "Epoch 96/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.0948 - acc: 0.9748\n",
      "Epoch 97/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.0818 - acc: 0.9761\n",
      "Epoch 98/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.0995 - acc: 0.9730\n",
      "Epoch 99/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.0901 - acc: 0.9751\n",
      "Epoch 100/100\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.0909 - acc: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa98f140be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 100, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1526/1526 [==============================] - 4s 2ms/step\n",
      "\n",
      "Test accuracy =  0.9567496721116462\n",
      "Loss =  0.18685297507836654\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sen_to_index(X_test, words_to_index, maxlen)\n",
    "Y_test_oh = np.eye(classes)[Y_test.reshape(-1)]\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)\n",
    "print(\"Loss = \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Entertainment news from india tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "ex = np.array(['Vicky Kaushal and Nora Fatehi are all set to spread their charm on The Kapil Sharma Show. The duo will grace the set of the popular show to promote their latest music video Pachtaoge. Nora and Vicky have collaborated for the first time for Arijit Singh song. They had a gala time chatting with Kapil Sharma and his team. Nora also grooved to some of her hit dance numbers.'])\n",
    "ex_in = sen_to_index(ex, words_to_index, maxlen)\n",
    "ex_pred = model.predict(ex_in)\n",
    "ex_pred = np.argmax(ex_pred, axis=1)\n",
    "print(ex_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('news_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trianed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"news_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 300, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300, 128)          91648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,798\n",
      "Trainable params: 223,748\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
