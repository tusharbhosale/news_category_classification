{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News category Prediction \n",
    "\n",
    "FEATURES:\n",
    "\n",
    "STORY:  A part of the main content of the article to be published as a piece of news.\n",
    "SECTION: The genre/category the STORY falls in.\n",
    "\n",
    "There are four distinct sections where each story may fall in to. The Sections are labelled as follows :\n",
    "\n",
    "Politics: 0\n",
    "\n",
    "Technology: 1\n",
    "\n",
    "Entertainment: 2\n",
    "\n",
    "Business: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('news_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the most painful was the huge reversal in ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How formidable is the opposition alliance amon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most Asian currencies were trading lower today...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you want to answer any question, click on ‘...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In global markets, gold prices edged up today ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               STORY  SECTION\n",
       "0  But the most painful was the huge reversal in ...        3\n",
       "1  How formidable is the opposition alliance amon...        0\n",
       "2  Most Asian currencies were trading lower today...        3\n",
       "3  If you want to answer any question, click on ‘...        1\n",
       "4  In global markets, gold prices edged up today ...        3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:1].values\n",
    "Y = df.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7628, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7628, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train ,Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 300\n",
    "classes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading glove vectors from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove(file):\n",
    "    with open(file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_index, index_to_words, word_to_vec_map = read_glove(\"glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting sentence into respective indices using glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen_to_index(X, words_to_index, maxlen):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, maxlen))\n",
    "    for i in range(0, m):\n",
    "        sent = X[i][0].replace('’', '').translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "        j = 0\n",
    "        for w in sent:\n",
    "            if w in words_to_index.keys():\n",
    "                X_indices[i, j] = words_to_index[w]\n",
    "            else:\n",
    "                X_indices[i, j] = words_to_index['unk']\n",
    "            j = j + 1\n",
    "            if j == maxlen:\n",
    "                break\n",
    "    return X_indices   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load require libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(word_to_vec_map, words_to_index):\n",
    "    \n",
    "    vocab = len(words_to_index) + 1\n",
    "    vec_size = len(word_to_vec_map[\"news\"])\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab, vec_size))\n",
    "    \n",
    "    for w, i in words_to_index.items():\n",
    "        embedding_matrix[i, :] = word_to_vec_map[w]\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim = vocab, output_dim = vec_size, trainable = False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([embedding_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Model for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_classifier(input_shape, word_to_vec_map, words_to_index):\n",
    "    \n",
    "    sen_indices = Input(input_shape, dtype = 'int32')\n",
    "    \n",
    "    embedding_layer = embedding(word_to_vec_map, words_to_index)\n",
    "    \n",
    "    embeddings = embedding_layer(sen_indices)\n",
    "    \n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(4)(X)\n",
    "    X = Activation(\"softmax\")(X)\n",
    "    \n",
    "    model = Model(sen_indices, X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 300, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 300, 128)          91648     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,798\n",
      "Trainable params: 223,748\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = news_classifier((maxlen,), word_to_vec_map, words_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sen_to_index(X_train, words_to_index, maxlen)\n",
    "Y_train_oh = np.eye(classes)[Y_train.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tushar/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/70\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 1.3360 - acc: 0.3827\n",
      "Epoch 2/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 1.1423 - acc: 0.5192\n",
      "Epoch 3/70\n",
      "6102/6102 [==============================] - 52s 8ms/step - loss: 1.1482 - acc: 0.5193\n",
      "Epoch 4/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 1.0671 - acc: 0.5456\n",
      "Epoch 5/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 1.1044 - acc: 0.5421\n",
      "Epoch 6/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 1.3199 - acc: 0.3984\n",
      "Epoch 7/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 1.3398 - acc: 0.3627\n",
      "Epoch 8/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 1.2120 - acc: 0.4664\n",
      "Epoch 9/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 1.1396 - acc: 0.5031\n",
      "Epoch 10/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.9945 - acc: 0.5737\n",
      "Epoch 11/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.8691 - acc: 0.6755\n",
      "Epoch 12/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.8218 - acc: 0.6608\n",
      "Epoch 13/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.9169 - acc: 0.6054\n",
      "Epoch 14/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.7545 - acc: 0.7145\n",
      "Epoch 15/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.6838 - acc: 0.7555\n",
      "Epoch 16/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.5702 - acc: 0.7840\n",
      "Epoch 17/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.5329 - acc: 0.7947\n",
      "Epoch 18/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.5313 - acc: 0.7915\n",
      "Epoch 19/70\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.5419 - acc: 0.8009\n",
      "Epoch 20/70\n",
      "6102/6102 [==============================] - 52s 9ms/step - loss: 0.4567 - acc: 0.8441\n",
      "Epoch 21/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.3365 - acc: 0.9084\n",
      "Epoch 22/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.3182 - acc: 0.9194\n",
      "Epoch 23/70\n",
      "6102/6102 [==============================] - 54s 9ms/step - loss: 0.2781 - acc: 0.9308\n",
      "Epoch 24/70\n",
      "6102/6102 [==============================] - 53s 9ms/step - loss: 0.2753 - acc: 0.9284\n",
      "Epoch 25/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2566 - acc: 0.9376\n",
      "Epoch 26/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2430 - acc: 0.9323\n",
      "Epoch 27/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2184 - acc: 0.9431\n",
      "Epoch 28/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2135 - acc: 0.9422\n",
      "Epoch 29/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1890 - acc: 0.9502\n",
      "Epoch 30/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1841 - acc: 0.9507\n",
      "Epoch 31/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2202 - acc: 0.9367\n",
      "Epoch 32/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1839 - acc: 0.9492\n",
      "Epoch 33/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1691 - acc: 0.9518\n",
      "Epoch 34/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1846 - acc: 0.9469\n",
      "Epoch 35/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1921 - acc: 0.9479\n",
      "Epoch 36/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2608 - acc: 0.9254\n",
      "Epoch 37/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1920 - acc: 0.9495\n",
      "Epoch 38/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1699 - acc: 0.9531\n",
      "Epoch 39/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1726 - acc: 0.9505\n",
      "Epoch 40/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1911 - acc: 0.9497\n",
      "Epoch 41/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1587 - acc: 0.9551\n",
      "Epoch 42/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1977 - acc: 0.9407\n",
      "Epoch 43/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1612 - acc: 0.9521\n",
      "Epoch 44/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1471 - acc: 0.9582\n",
      "Epoch 45/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1529 - acc: 0.9598\n",
      "Epoch 46/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1434 - acc: 0.9594\n",
      "Epoch 47/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1227 - acc: 0.9651\n",
      "Epoch 48/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1340 - acc: 0.9635\n",
      "Epoch 49/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.3807 - acc: 0.8922\n",
      "Epoch 50/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.2563 - acc: 0.9246\n",
      "Epoch 51/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1908 - acc: 0.9438\n",
      "Epoch 52/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1594 - acc: 0.9531\n",
      "Epoch 53/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1892 - acc: 0.9472\n",
      "Epoch 54/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1438 - acc: 0.9554\n",
      "Epoch 55/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1558 - acc: 0.9530\n",
      "Epoch 56/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1736 - acc: 0.9477\n",
      "Epoch 57/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1455 - acc: 0.9574\n",
      "Epoch 58/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1467 - acc: 0.9558\n",
      "Epoch 59/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1579 - acc: 0.9539\n",
      "Epoch 60/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1342 - acc: 0.9615\n",
      "Epoch 61/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1243 - acc: 0.9633\n",
      "Epoch 62/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1185 - acc: 0.9635\n",
      "Epoch 63/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1201 - acc: 0.9662\n",
      "Epoch 64/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1170 - acc: 0.9666\n",
      "Epoch 65/70\n",
      "6102/6102 [==============================] - 51s 8ms/step - loss: 0.1090 - acc: 0.9680\n",
      "Epoch 66/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1082 - acc: 0.9676\n",
      "Epoch 67/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1098 - acc: 0.9677\n",
      "Epoch 68/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.1035 - acc: 0.9672\n",
      "Epoch 69/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.0988 - acc: 0.9687\n",
      "Epoch 70/70\n",
      "6102/6102 [==============================] - 50s 8ms/step - loss: 0.0945 - acc: 0.9726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f33ae398080>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 70, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1526/1526 [==============================] - 4s 3ms/step\n",
      "\n",
      "Test accuracy =  0.9469200521902832\n",
      "Loss =  0.19833273354668762\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sen_to_index(X_test, words_to_index, maxlen)\n",
    "Y_test_oh = np.eye(classes)[Y_test.reshape(-1)]\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)\n",
    "print(\"Loss = \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Entertainment news from india tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "ex = np.array(['Vicky Kaushal and Nora Fatehi are all set to spread their charm on The Kapil Sharma Show. The duo will grace the set of the popular show to promote their latest music video Pachtaoge. Nora and Vicky have collaborated for the first time for Arijit Singh song. They had a gala time chatting with Kapil Sharma and his team. Nora also grooved to some of her hit dance numbers.'])\n",
    "ex_in = sen_to_index(ex, words_to_index, maxlen)\n",
    "ex_pred = model.predict(ex_in)\n",
    "ex_pred = np.argmax(ex_pred, axis=1)\n",
    "print(ex_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('news_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trianed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"news_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 300, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 300, 128)          91648     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,798\n",
      "Trainable params: 223,748\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
